{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict FLSA code with job descriptions and compensation\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import os\n",
    "import bert\n",
    "from bert import BertModelLayer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Input, Lambda, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "import tqdm\n",
    "\n",
    "## Code will work with either tensorflow version, but needs to be executed eagerly if 1.X\n",
    "if tf.__version__[0] == '1':\n",
    "    tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_strat(type='cpu', tpu=None, zone=None, project=None):\n",
    "    if type == 'cpu':\n",
    "        return tf.distribute.OneDeviceStrategy(device='/cpu:0')\n",
    "    elif type == 'gpu':\n",
    "        return tf.distribute.OneDeviceStrategy(device='/gpu:0')\n",
    "    elif type == 'tpu':\n",
    "        cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "            tpu=tpu, zone=zone, project=project)\n",
    "        tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "        tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "        tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
    "        return tpu_strategy\n",
    "    elif type == 'mirror':\n",
    "        return tf.distribute.MirroredStrategy(devices=['/gpu:0', '/gpu:1'])\n",
    "    else:\n",
    "        raise ValueError('Available strategy types are cpu, gpu, tpu, and mirror')\n",
    "\n",
    "class DenseBlock(keras.layers.Layer):\n",
    "    def __init__(self, units, activation='elu', momentum=0.9, dropout=0.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.momentum = momentum\n",
    "        self.dropout = dropout\n",
    "        self.dense_x = Dense(units=units, activation=None, kernel_initializer='he_normal')\n",
    "        self.bn_x = BatchNormalization(momentum=momentum)\n",
    "        self.activ_x = Activation(activation)\n",
    "        self.drop_x = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_x(inputs)\n",
    "        x = self.bn_x(x)\n",
    "        x = self.activ_x(x)\n",
    "        return self.drop_x(x)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'units': self.units,\n",
    "            'activation': self.activation,\n",
    "            'momentum': self.momentum,\n",
    "            'dropout': self.dropout,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def build_model(strategy, lr, activation, n_layers=3, layer_units=None):\n",
    "    if layer_units is None:\n",
    "        layer_units = [100] * n_layers\n",
    "    with strategy.scope():\n",
    "        with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
    "            bc = bert.loader.StockBertConfig.from_json_string(reader.read())\n",
    "            bert_params = bert.loader.map_stock_config_to_params(bc)\n",
    "            bert_layer = BertModelLayer().from_params(bert_params, name='bert')\n",
    "\n",
    "        bert_in = Input(shape=(max_seq_len,), dtype='int32', name=\"bert_input\")\n",
    "        bert_out = bert_layer(bert_in)\n",
    "        bert_out = Lambda(lambda seq: seq[:, 0, :])(bert_out)\n",
    "        bert_out = Dropout(0.5)(bert_out)\n",
    "\n",
    "        comp_in = Input(shape=(1), dtype='float32', name='comp_input')\n",
    "        x = keras.layers.concatenate([bert_out, comp_in])\n",
    "        x = DenseBlock(units=769, activation=activation)(x)\n",
    "        for n in range(n_layers):\n",
    "            x = DenseBlock(\n",
    "                units=layer_units[n], \n",
    "                activation=activation, \n",
    "                name='dense{}'.format(n))(x)\n",
    "        out = Dense(units=n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "        model = keras.Model(inputs=[bert_in, comp_in], outputs=out)\n",
    "        bert.loader.load_stock_weights(bert_layer, bert_ckpt_file)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=keras.optimizers.Adam(lr),\n",
    "                      metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def deep_eval(model, threshold):\n",
    "    \n",
    "    def filtered_acc(thresh):\n",
    "        acc_list = []\n",
    "        for i, val in enumerate(pred_vals): \n",
    "            if preds[i, np.argmax(y_test[i])] > thresh:\n",
    "                acc_list.append(val == y_vals[i])\n",
    "        return np.mean(acc_list)\n",
    "        \n",
    "    preds = model.predict(X_test)\n",
    "    y_vals = np.array([classes[np.argmax(i)] for i in y_test])\n",
    "    pred_vals = np.array([classes[np.argmax(i)] for i in preds])\n",
    "    plain_acc = (y_vals == pred_vals).mean()\n",
    "    print('Plain test accuracy:', plain_acc)\n",
    "    thresh_acc = filtered_acc(threshold)\n",
    "    print('Test accuracy when probability is above {} threshold: {}'.format(threshold, thresh_acc))\n",
    "    null_class_acc = {}\n",
    "    for col in classes:\n",
    "        null_class_acc[col] = []\n",
    "        for i, x in enumerate(pred_vals):\n",
    "            if x == col:\n",
    "                null_class_acc[col].append(x == y_vals[i])\n",
    "\n",
    "    filt_class_acc = {}\n",
    "    for col in classes:\n",
    "        filt_class_acc[col] = []\n",
    "        for i, x in enumerate(pred_vals):\n",
    "            if x == col and preds[i, np.argmax(y_test[i])] > .5:\n",
    "                filt_class_acc[col].append(x == y_vals[i])\n",
    "    import pandas as pd\n",
    "    performance = {\n",
    "        'class': [],\n",
    "        'filtered_len': [],\n",
    "        'total_len': [],\n",
    "        'filtered_acc': [],\n",
    "        'total_acc': [],\n",
    "        'retain_pct': []\n",
    "    }\n",
    "    for label in classes:\n",
    "        if len(null_class_acc[label]) == 0:\n",
    "            print('Group', label, 'not predicted for any instance')\n",
    "            continue\n",
    "        performance['class'].append(label)\n",
    "        performance['filtered_len'].append(len(filt_class_acc[label]))\n",
    "        performance['total_len'].append(len(null_class_acc[label]))\n",
    "        performance['filtered_acc'].append(np.mean(filt_class_acc[label]))\n",
    "        performance['total_acc'].append(np.mean(null_class_acc[label]))\n",
    "        performance['retain_pct'].append(len(filt_class_acc[label]) / len(null_class_acc[label]) * 100)\n",
    "        performance_df = pd.DataFrame(performance)\n",
    "    performance_df = performance_df.sort_values('total_len')\n",
    "    use_pct = performance_df.filtered_len.sum() / performance_df.total_len.sum()\n",
    "    print('Ratio of predictions that would be used:', use_pct)\n",
    "    return performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>Define Environment Variables and Hyperparameters</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Environment Variables\n",
    "distr_strat = 'cpu'\n",
    "do_train = True\n",
    "do_eval = True\n",
    "\n",
    "## BERT Params\n",
    "model_id = 2\n",
    "from_scratch = True\n",
    "bert_type = 'uncased_base'\n",
    "do_lower_case = True\n",
    "max_seq_len = 256\n",
    "bert_epochs = 3\n",
    "activ = 'elu'\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "lr = 5e-4\n",
    "n_layers = 3\n",
    "layer_units = [300, 150, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up files, file names, and directories to be referenced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Include strategy variables if tpu\n",
    "if distr_strat == 'tpu':\n",
    "    tpu_name = 'node-2'\n",
    "    tpu_zone = 'us-central1-c'\n",
    "    tpu_proj = 'cedar-pottery-252818'\n",
    "else:\n",
    "    tpu_name = None\n",
    "    tpu_zone = None\n",
    "    tpu_proj = None\n",
    "\n",
    "## Relevant directories - saved model metadata in model_comparison.xlsx by id\n",
    "proj_dir = 'gs://eri-ml-bucket-1/flsa_prediction'\n",
    "data_dir = os.path.join(proj_dir, 'data')\n",
    "tf.io.gfile.makedirs('saved_models')\n",
    "model_file = os.path.join('saved_models', 'model.{:02d}.h5'.format(model_id))\n",
    "if not from_scratch and not tf.io.gfile.exists(model_file):\n",
    "    tf.io.gfile.copy(os.path.join(proj_dir, model_file), model_file)\n",
    "\n",
    "## BERT pretrained files\n",
    "bert_dir = os.path.join(os.getcwd(), 'data', bert_type)\n",
    "bert_ckpt_file = os.path.join(bert_dir, 'bert_model.ckpt')\n",
    "bert_config_file = os.path.join(bert_dir, 'bert_config.json')\n",
    "bert_vocab_file = os.path.join(bert_dir, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load raw data from GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_train:\n",
    "    file = os.path.join(data_dir, 'bert_input_train.npy')\n",
    "    with tf.io.gfile.GFile(file, 'rb') as f:\n",
    "        bert_input_train = np.load(f, allow_pickle=True)\n",
    "    file = os.path.join(data_dir, 'comp_input_train.npy')\n",
    "    with tf.io.gfile.GFile(file, 'rb') as f:\n",
    "        comp_input_train = np.load(f, allow_pickle=True)\n",
    "    file = os.path.join(data_dir, 'y_train.npy')\n",
    "    with tf.io.gfile.GFile(file, 'rb') as f:\n",
    "        y_train = np.load(f, allow_pickle=True)\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        ({'bert_input': bert_input_train,\n",
    "        'comp_input': comp_input_train},\n",
    "        y_train))\n",
    "    train_ds = train_ds.shuffle(buffer_size=100).batch(batch_size)\n",
    "    train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    train_size = len(y_train)\n",
    "    del bert_input_train, comp_input_train, y_train\n",
    "    \n",
    "    file = os.path.join(data_dir, 'bert_input_valid.npy')\n",
    "    with tf.io.gfile.GFile(file, 'rb') as f:\n",
    "        bert_input_valid = np.load(f, allow_pickle=True)\n",
    "    file = os.path.join(data_dir, 'comp_input_valid.npy')\n",
    "    with tf.io.gfile.GFile(file, 'rb') as f:\n",
    "        comp_input_valid = np.load(f, allow_pickle=True)\n",
    "    file = os.path.join(data_dir, 'y_valid.npy')\n",
    "    with tf.io.gfile.GFile(file, 'rb') as f:\n",
    "        y_valid = np.load(f, allow_pickle=True)\n",
    "    valid_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        ({'bert_input': bert_input_valid,\n",
    "        'comp_input': comp_input_valid},\n",
    "        y_valid))\n",
    "    valid_ds = valid_ds.shuffle(buffer_size=100).batch(batch_size)\n",
    "    valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    valid_size = len(y_valid)\n",
    "    del bert_input_valid, comp_input_valid, y_valid\n",
    "    \n",
    "if do_eval:\n",
    "    file = os.path.join(data_dir, 'bert_input_test.npy')\n",
    "    with tf.io.gfile.GFile(file, 'rb') as f:\n",
    "        bert_input_test = np.load(f, allow_pickle=True)\n",
    "    file = os.path.join(data_dir, 'comp_input_test.npy')\n",
    "    with tf.io.gfile.GFile(file, 'rb') as f:\n",
    "        comp_input_test = np.load(f, allow_pickle=True)\n",
    "    file = os.path.join(data_dir, 'y_test.npy')\n",
    "    with tf.io.gfile.GFile(file, 'rb') as f:\n",
    "        y_test = np.load(f, allow_pickle=True)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        ({'bert_input': bert_input_test,\n",
    "        'comp_input': comp_input_test},\n",
    "        y_test))\n",
    "    test_ds = test_ds.shuffle(buffer_size=100).batch(batch_size)\n",
    "    test_ds = test_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    test_size = len(y_test)\n",
    "    del bert_input_test, comp_input_test, y_test\n",
    "\n",
    "file = os.path.join(data_dir, 'classes.npy')\n",
    "with tf.io.gfile.GFile(file, 'rb') as f:\n",
    "    classes = np.load(f, allow_pickle=True)\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Fine-Tuning\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build pure BERT model from \"scratch\" or load previous h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = build_strat(type=distr_strat, tpu=tpu_name, zone=tpu_zone, project=tpu_proj)\n",
    "if from_scratch:\n",
    "    model = build_model(strat, lr, activ, n_layers=n_layers, layer_units=layer_units)\n",
    "else:\n",
    "    model = keras.models.load_model(model_file, custom_objects={'BertModelLayer': bert.BertModelLayer,\n",
    "                                                                'DenseBlock': DenseBlock})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model, saving the epoch with the highest accuracy locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=bert_epochs)\n",
    "\n",
    "trained_bert_file = os.path.join('saved_models', 'trained_bert_model.{:02d}.h5'.format(model_id))\n",
    "model.save(trained_bert_file)\n",
    "tf.io.gfile.copy(trained_bert_file, os.path.join(proj_dir, trained_bert_file), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].trainable = False\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.001,\n",
    "    patience=7,\n",
    "    restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=model_file,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True)\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=epochs, \n",
    "    initial_epoch=bert_epochs, \n",
    "    callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.gfile.copy(model_file, os.path.join(proj_dir, model_file), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>Update GCP with the latest version of this script</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.gfile.copy('model.ipynb', os.path.join(proj_dir, 'model.ipynb'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_model = os.path.join('saved_models', 'model_{%02d}'.format(model_id))\n",
    "model.save(serve_model, save_format='tf')\n",
    "!gsutil -m cp -R $serve_model gs://eri-ml-bucket-1/ml_job_match/$serve_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
